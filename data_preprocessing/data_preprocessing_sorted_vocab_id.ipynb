{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook generates the train and test dataset,  \n",
    "# which user_vocab_id and movie_vocab_id are sorted by user and movie frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping old uid to new uid sorted by old uid frequency in train_data.dat\n",
    "\n",
    "def mapping_id_by_sorted_freq(src_doc, mapping_doc, feature_idx, mapping):\n",
    "    freq_cnt = {}\n",
    "    with open('../data/train_data.dat', 'r') as file:\n",
    "        rows = csv.reader(file,delimiter=':')\n",
    "        for row in rows:\n",
    "            old_vocab_id = row[feature_idx]\n",
    "            freq_cnt[old_vocab_id] = freq_cnt.get(old_vocab_id, 0) + 1\n",
    "    freq_cnt = [(old_vocab_id, cnt) for old_vocab_id, cnt in freq_cnt.items()]\n",
    "    freq_cnt.sort(key = lambda x: x[1], reverse = True)\n",
    "    for new_vocab_id, item in enumerate(freq_cnt):\n",
    "        old_vocab_id, cnt = item\n",
    "        mapping[old_vocab_id] = str(new_vocab_id+1)\n",
    "\n",
    "    open(mapping_doc, 'w').close()\n",
    "    outF = open(mapping_doc, 'w')\n",
    "    with open(src_doc, 'r') as file:\n",
    "        rows = csv.reader(file, delimiter='^')\n",
    "        for row in rows:\n",
    "            old_vocab_id = row[0]\n",
    "            if old_vocab_id in mapping:\n",
    "                new_row = [old_vocab_id, mapping[old_vocab_id]]\n",
    "                new_row.extend(row[1:])\n",
    "                new_row = ':'.join(new_row)\n",
    "                outF.write(new_row)\n",
    "                outF.write(\"\\n\")\n",
    "        outF.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace old vocab id to new vocab id (popularity hashing id)ã€‚\n",
    "\n",
    "def replace_old_vocab_id_with_popularity_hashing_id(source_doc, dest_doc, feature_idxs, mappings): \n",
    "    open(dest_doc, 'w').close()\n",
    "\n",
    "    assert len(feature_idxs) == len(mappings)\n",
    "    outF = open(dest_doc,'w')\n",
    "    with open(source_doc, 'r') as file:\n",
    "        rows = csv.reader(file,delimiter=':')\n",
    "        for row in rows:\n",
    "            for feature_idx, mapping in zip(feature_idxs, mappings):\n",
    "                old_vocab_id = row[feature_idx]\n",
    "                row = row[:feature_idx] + [mapping[old_vocab_id]] + row[feature_idx+1:]\n",
    "            outF.write(\":\".join(row) + '\\n')\n",
    "        outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_replace_doc_source = 'train_data.dat'\n",
    "movie_replace_doc_source = 'data_sorted_user.dat'\n",
    "resorted_data_doc = 'data_sorted.dat'\n",
    "user_mapping, movie_mapping = {}, {}\n",
    "mapping_id_by_sorted_freq('../data/users.dat', '../data/user_id_mapping.dat', 0, user_mapping)\n",
    "mapping_id_by_sorted_freq('../data/movies.dat', '../data/movie_id_mapping.dat', 1, movie_mapping)\n",
    "replace_old_vocab_id_with_popularity_hashing_id('../data/train_data.dat', '../data/train_data_sorted_vocab_id.dat', [0, 1], [user_mapping, movie_mapping])\n",
    "replace_old_vocab_id_with_popularity_hashing_id('../data/test_data.dat', '../data/test_data_sorted_vocab_id.dat', [0, 1], [user_mapping, movie_mapping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39310 32158\n"
     ]
    }
   ],
   "source": [
    "# write metrics to train_meta_data.dat\n",
    "######metadata.dat########\n",
    "# num_user:69280\n",
    "# num_movie:36365\n",
    "# num_category:28\n",
    "######metadata.dat########\n",
    "num_user, num_movie, num_category = 0, 0, 28\n",
    "with open('../data/user_id_mapping.dat', 'r') as f:\n",
    "    for line in f:\n",
    "        num_user += 1\n",
    "with open('../data/movie_id_mapping.dat', 'r') as f:\n",
    "    for line in f:\n",
    "        num_movie += 1\n",
    "print(num_user, num_movie)\n",
    "        \n",
    "keys = ['num_user', 'num_movie', 'num_category']\n",
    "values = [num_user, num_movie, num_category]\n",
    "open('../data/train_meta_data.dat', 'w').close()\n",
    "with open(\"../data/train_meta_data.dat\", \"w\") as file:\n",
    "    for i in range(3):\n",
    "        file.write(keys[i] + \":\" + str(values[i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping movie new vocab id to movie name\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
